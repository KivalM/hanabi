{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import tempfile\n",
    "\n",
    "import torch\n",
    "\n",
    "# from matplotlib import pyplot as plt\n",
    "from tensordict import TensorDictBase\n",
    "\n",
    "from tensordict.nn import TensorDictModule, TensorDictSequential\n",
    "from torch import multiprocessing\n",
    "\n",
    "from torchrl.collectors import SyncDataCollector\n",
    "from torchrl.data import LazyMemmapStorage, RandomSampler, ReplayBuffer\n",
    "\n",
    "from torchrl.envs import (\n",
    "    check_env_specs,\n",
    "    ExplorationType,\n",
    "    PettingZooEnv,\n",
    "    RewardSum,\n",
    "    set_exploration_type,\n",
    "    TransformedEnv,\n",
    "    VmasEnv,\n",
    ")\n",
    "\n",
    "from torchrl.modules import (\n",
    "    AdditiveGaussianModule,\n",
    "    MultiAgentMLP,\n",
    "    ProbabilisticActor,\n",
    "    TanhDelta,\n",
    ")\n",
    "\n",
    "from torchrl.objectives import DDPGLoss, SoftUpdate, ValueEstimators\n",
    "\n",
    "from torchrl.record import CSVLogger, PixelRenderTransform, VideoRecorder\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Seed\n",
    "seed = 0\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# Devices\n",
    "is_fork = multiprocessing.get_start_method() == \"fork\"\n",
    "device = (\n",
    "    torch.device(0)\n",
    "    if torch.cuda.is_available() and not is_fork\n",
    "    else torch.device(\"cpu\")\n",
    ")\n",
    "print(f\"Using device: {device}\")\n",
    "# Sampling\n",
    "frames_per_batch = 1_000  # Number of team frames collected per sampling iteration\n",
    "n_iters = 10  # Number of sampling and training iterations\n",
    "total_frames = frames_per_batch * n_iters\n",
    "\n",
    "# We will stop training the evaders after this many iterations,\n",
    "# should be 0 <= iteration_when_stop_training_evaders <= n_iters\n",
    "iteration_when_stop_training_evaders = n_iters // 2\n",
    "\n",
    "# Replay buffer\n",
    "memory_size = 1_000_000  # The replay buffer of each group can store this many frames\n",
    "\n",
    "# Training\n",
    "n_optimiser_steps = 100  # Number of optimisation steps per training iteration\n",
    "train_batch_size = 128  # Number of frames trained in each optimiser step\n",
    "lr = 3e-4  # Learning rate\n",
    "max_grad_norm = 1.0  # Maximum norm for the gradients\n",
    "\n",
    "# DDPG\n",
    "gamma = 0.99  # Discount factor\n",
    "polyak_tau = 0.005  # Tau for the soft-update of the target network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchrl.envs import PettingZooEnv, MarlGroupMapType\n",
    "\n",
    "scenario_name = \"hanabi_v5\"\n",
    "num_players = 2\n",
    "num_ranks = 5\n",
    "num_colors = 2\n",
    "hand_size = 2\n",
    "render_mode = \"human\"\n",
    "\n",
    "base_env = PettingZooEnv(\n",
    "    task=scenario_name,\n",
    "    parallel=False,\n",
    "    use_mask=True,\n",
    "    players=num_players,\n",
    "    ranks=num_ranks,\n",
    "    colors=num_colors,\n",
    "    hand_size=hand_size,\n",
    "    max_life_tokens=1,\n",
    "    max_information_tokens=3,\n",
    "    categorical_actions=True,\n",
    "    seed=0,\n",
    "    done_on_any=True,\n",
    "    # group_map=MarlGroupMapType.ALL_IN_ONE_GROUP,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_reset', ('player_0', '_reset'), ('player_1', '_reset')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_env.reset_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchrl.envs.transforms import DoubleToFloat, StepCounter\n",
    "\n",
    "env = TransformedEnv(\n",
    "    base_env,\n",
    "    # DoubleToFloat(),\n",
    "    # StepCounter(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        done: Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
       "        player_0: TensorDict(\n",
       "            fields={\n",
       "                action_mask: Tensor(shape=torch.Size([1, 11]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
       "                done: Tensor(shape=torch.Size([1, 1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
       "                mask: Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
       "                observation: TensorDict(\n",
       "                    fields={\n",
       "                        observation: Tensor(shape=torch.Size([1, 171]), device=cuda:0, dtype=torch.float64, is_shared=True)},\n",
       "                    batch_size=torch.Size([1]),\n",
       "                    device=cuda:0,\n",
       "                    is_shared=True),\n",
       "                terminated: Tensor(shape=torch.Size([1, 1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
       "                truncated: Tensor(shape=torch.Size([1, 1]), device=cuda:0, dtype=torch.bool, is_shared=True)},\n",
       "            batch_size=torch.Size([1]),\n",
       "            device=cuda:0,\n",
       "            is_shared=True),\n",
       "        player_1: TensorDict(\n",
       "            fields={\n",
       "                action_mask: Tensor(shape=torch.Size([1, 11]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
       "                done: Tensor(shape=torch.Size([1, 1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
       "                mask: Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
       "                observation: TensorDict(\n",
       "                    fields={\n",
       "                        observation: Tensor(shape=torch.Size([1, 171]), device=cuda:0, dtype=torch.float64, is_shared=True)},\n",
       "                    batch_size=torch.Size([1]),\n",
       "                    device=cuda:0,\n",
       "                    is_shared=True),\n",
       "                terminated: Tensor(shape=torch.Size([1, 1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
       "                truncated: Tensor(shape=torch.Size([1, 1]), device=cuda:0, dtype=torch.bool, is_shared=True)},\n",
       "            batch_size=torch.Size([1]),\n",
       "            device=cuda:0,\n",
       "            is_shared=True),\n",
       "        terminated: Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
       "        truncated: Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.bool, is_shared=True)},\n",
       "    batch_size=torch.Size([]),\n",
       "    device=cuda:0,\n",
       "    is_shared=True)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from numpy import random\n",
    "class RandomPolicy(nn.Module):\n",
    "    def __init__(self, action_space):\n",
    "        super().__init__()\n",
    "        self.action_space = action_space\n",
    "\n",
    "    def forward(self, obs, action_mask):\n",
    "        # choose one of the legal actions uniformly at random from the action mask ([true, false, true] -> [0, 2])\n",
    "        action_mask = action_mask.squeeze()\n",
    "        action_mask = action_mask.bool()\n",
    "        action_mask = action_mask.cpu().numpy()\n",
    "        action = random.choice(len(action_mask), p=action_mask/sum(action_mask))\n",
    "        \n",
    "        return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "player_0\n",
      "tensor([False], device='cuda:0')\n",
      "9\n",
      "TensorDict(\n",
      "    fields={\n",
      "        next: TensorDict(\n",
      "            fields={\n",
      "                done: Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "                player_0: TensorDict(\n",
      "                    fields={\n",
      "                        action_mask: Tensor(shape=torch.Size([1, 11]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "                        done: Tensor(shape=torch.Size([1, 1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "                        mask: Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "                        observation: TensorDict(\n",
      "                            fields={\n",
      "                                observation: Tensor(shape=torch.Size([1, 171]), device=cuda:0, dtype=torch.float64, is_shared=True)},\n",
      "                            batch_size=torch.Size([1]),\n",
      "                            device=cuda:0,\n",
      "                            is_shared=True),\n",
      "                        reward: Tensor(shape=torch.Size([1, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        terminated: Tensor(shape=torch.Size([1, 1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "                        truncated: Tensor(shape=torch.Size([1, 1]), device=cuda:0, dtype=torch.bool, is_shared=True)},\n",
      "                    batch_size=torch.Size([1]),\n",
      "                    device=cuda:0,\n",
      "                    is_shared=True),\n",
      "                player_1: TensorDict(\n",
      "                    fields={\n",
      "                        action_mask: Tensor(shape=torch.Size([1, 11]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "                        done: Tensor(shape=torch.Size([1, 1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "                        mask: Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "                        observation: TensorDict(\n",
      "                            fields={\n",
      "                                observation: Tensor(shape=torch.Size([1, 171]), device=cuda:0, dtype=torch.float64, is_shared=True)},\n",
      "                            batch_size=torch.Size([1]),\n",
      "                            device=cuda:0,\n",
      "                            is_shared=True),\n",
      "                        reward: Tensor(shape=torch.Size([1, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        terminated: Tensor(shape=torch.Size([1, 1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "                        truncated: Tensor(shape=torch.Size([1, 1]), device=cuda:0, dtype=torch.bool, is_shared=True)},\n",
      "                    batch_size=torch.Size([1]),\n",
      "                    device=cuda:0,\n",
      "                    is_shared=True),\n",
      "                terminated: Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "                truncated: Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.bool, is_shared=True)},\n",
      "            batch_size=torch.Size([]),\n",
      "            device=cuda:0,\n",
      "            is_shared=True),\n",
      "        player_0: TensorDict(\n",
      "            fields={\n",
      "                action: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.int64, is_shared=False)},\n",
      "            batch_size=torch.Size([]),\n",
      "            device=None,\n",
      "            is_shared=False)},\n",
      "    batch_size=torch.Size([]),\n",
      "    device=None,\n",
      "    is_shared=False)\n",
      "player_1\n",
      "tensor([False], device='cuda:0')\n",
      "4\n",
      "TensorDict(\n",
      "    fields={\n",
      "        next: TensorDict(\n",
      "            fields={\n",
      "                done: Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "                player_0: TensorDict(\n",
      "                    fields={\n",
      "                        action_mask: Tensor(shape=torch.Size([1, 11]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "                        done: Tensor(shape=torch.Size([1, 1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "                        mask: Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "                        observation: TensorDict(\n",
      "                            fields={\n",
      "                                observation: Tensor(shape=torch.Size([1, 171]), device=cuda:0, dtype=torch.float64, is_shared=True)},\n",
      "                            batch_size=torch.Size([1]),\n",
      "                            device=cuda:0,\n",
      "                            is_shared=True),\n",
      "                        reward: Tensor(shape=torch.Size([1, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        terminated: Tensor(shape=torch.Size([1, 1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "                        truncated: Tensor(shape=torch.Size([1, 1]), device=cuda:0, dtype=torch.bool, is_shared=True)},\n",
      "                    batch_size=torch.Size([1]),\n",
      "                    device=cuda:0,\n",
      "                    is_shared=True),\n",
      "                player_1: TensorDict(\n",
      "                    fields={\n",
      "                        action_mask: Tensor(shape=torch.Size([1, 11]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "                        done: Tensor(shape=torch.Size([1, 1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "                        mask: Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "                        observation: TensorDict(\n",
      "                            fields={\n",
      "                                observation: Tensor(shape=torch.Size([1, 171]), device=cuda:0, dtype=torch.float64, is_shared=True)},\n",
      "                            batch_size=torch.Size([1]),\n",
      "                            device=cuda:0,\n",
      "                            is_shared=True),\n",
      "                        reward: Tensor(shape=torch.Size([1, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        terminated: Tensor(shape=torch.Size([1, 1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "                        truncated: Tensor(shape=torch.Size([1, 1]), device=cuda:0, dtype=torch.bool, is_shared=True)},\n",
      "                    batch_size=torch.Size([1]),\n",
      "                    device=cuda:0,\n",
      "                    is_shared=True),\n",
      "                terminated: Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "                truncated: Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.bool, is_shared=True)},\n",
      "            batch_size=torch.Size([]),\n",
      "            device=cuda:0,\n",
      "            is_shared=True),\n",
      "        player_1: TensorDict(\n",
      "            fields={\n",
      "                action: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.int64, is_shared=False)},\n",
      "            batch_size=torch.Size([]),\n",
      "            device=None,\n",
      "            is_shared=False)},\n",
      "    batch_size=torch.Size([]),\n",
      "    device=None,\n",
      "    is_shared=False)\n",
      "player_0\n",
      "tensor([False], device='cuda:0')\n",
      "1\n",
      "TensorDict(\n",
      "    fields={\n",
      "        next: TensorDict(\n",
      "            fields={\n",
      "                done: Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "                player_0: TensorDict(\n",
      "                    fields={\n",
      "                        action_mask: Tensor(shape=torch.Size([1, 11]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "                        done: Tensor(shape=torch.Size([1, 1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "                        mask: Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "                        observation: TensorDict(\n",
      "                            fields={\n",
      "                                observation: Tensor(shape=torch.Size([1, 171]), device=cuda:0, dtype=torch.float64, is_shared=True)},\n",
      "                            batch_size=torch.Size([1]),\n",
      "                            device=cuda:0,\n",
      "                            is_shared=True),\n",
      "                        reward: Tensor(shape=torch.Size([1, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        terminated: Tensor(shape=torch.Size([1, 1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "                        truncated: Tensor(shape=torch.Size([1, 1]), device=cuda:0, dtype=torch.bool, is_shared=True)},\n",
      "                    batch_size=torch.Size([1]),\n",
      "                    device=cuda:0,\n",
      "                    is_shared=True),\n",
      "                player_1: TensorDict(\n",
      "                    fields={\n",
      "                        action_mask: Tensor(shape=torch.Size([1, 11]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "                        done: Tensor(shape=torch.Size([1, 1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "                        mask: Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "                        observation: TensorDict(\n",
      "                            fields={\n",
      "                                observation: Tensor(shape=torch.Size([1, 171]), device=cuda:0, dtype=torch.float64, is_shared=True)},\n",
      "                            batch_size=torch.Size([1]),\n",
      "                            device=cuda:0,\n",
      "                            is_shared=True),\n",
      "                        reward: Tensor(shape=torch.Size([1, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        terminated: Tensor(shape=torch.Size([1, 1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "                        truncated: Tensor(shape=torch.Size([1, 1]), device=cuda:0, dtype=torch.bool, is_shared=True)},\n",
      "                    batch_size=torch.Size([1]),\n",
      "                    device=cuda:0,\n",
      "                    is_shared=True),\n",
      "                terminated: Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "                truncated: Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.bool, is_shared=True)},\n",
      "            batch_size=torch.Size([]),\n",
      "            device=cuda:0,\n",
      "            is_shared=True),\n",
      "        player_0: TensorDict(\n",
      "            fields={\n",
      "                action: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.int64, is_shared=False)},\n",
      "            batch_size=torch.Size([]),\n",
      "            device=None,\n",
      "            is_shared=False)},\n",
      "    batch_size=torch.Size([]),\n",
      "    device=None,\n",
      "    is_shared=False)\n",
      "player_1\n",
      "tensor([False], device='cuda:0')\n",
      "0\n",
      "TensorDict(\n",
      "    fields={\n",
      "        next: TensorDict(\n",
      "            fields={\n",
      "                done: Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "                player_0: TensorDict(\n",
      "                    fields={\n",
      "                        action_mask: Tensor(shape=torch.Size([1, 11]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "                        done: Tensor(shape=torch.Size([1, 1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "                        mask: Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "                        observation: TensorDict(\n",
      "                            fields={\n",
      "                                observation: Tensor(shape=torch.Size([1, 171]), device=cuda:0, dtype=torch.float64, is_shared=True)},\n",
      "                            batch_size=torch.Size([1]),\n",
      "                            device=cuda:0,\n",
      "                            is_shared=True),\n",
      "                        reward: Tensor(shape=torch.Size([1, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        terminated: Tensor(shape=torch.Size([1, 1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "                        truncated: Tensor(shape=torch.Size([1, 1]), device=cuda:0, dtype=torch.bool, is_shared=True)},\n",
      "                    batch_size=torch.Size([1]),\n",
      "                    device=cuda:0,\n",
      "                    is_shared=True),\n",
      "                player_1: TensorDict(\n",
      "                    fields={\n",
      "                        action_mask: Tensor(shape=torch.Size([1, 11]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "                        done: Tensor(shape=torch.Size([1, 1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "                        mask: Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "                        observation: TensorDict(\n",
      "                            fields={\n",
      "                                observation: Tensor(shape=torch.Size([1, 171]), device=cuda:0, dtype=torch.float64, is_shared=True)},\n",
      "                            batch_size=torch.Size([1]),\n",
      "                            device=cuda:0,\n",
      "                            is_shared=True),\n",
      "                        reward: Tensor(shape=torch.Size([1, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        terminated: Tensor(shape=torch.Size([1, 1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "                        truncated: Tensor(shape=torch.Size([1, 1]), device=cuda:0, dtype=torch.bool, is_shared=True)},\n",
      "                    batch_size=torch.Size([1]),\n",
      "                    device=cuda:0,\n",
      "                    is_shared=True),\n",
      "                terminated: Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "                truncated: Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.bool, is_shared=True)},\n",
      "            batch_size=torch.Size([]),\n",
      "            device=cuda:0,\n",
      "            is_shared=True),\n",
      "        player_1: TensorDict(\n",
      "            fields={\n",
      "                action: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.int64, is_shared=False)},\n",
      "            batch_size=torch.Size([]),\n",
      "            device=None,\n",
      "            is_shared=False)},\n",
      "    batch_size=torch.Size([]),\n",
      "    device=None,\n",
      "    is_shared=False)\n",
      "player_0\n",
      "tensor([False], device='cuda:0')\n",
      "5\n",
      "TensorDict(\n",
      "    fields={\n",
      "        next: TensorDict(\n",
      "            fields={\n",
      "                done: Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "                player_0: TensorDict(\n",
      "                    fields={\n",
      "                        action_mask: Tensor(shape=torch.Size([1, 11]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "                        done: Tensor(shape=torch.Size([1, 1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "                        mask: Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "                        observation: TensorDict(\n",
      "                            fields={\n",
      "                                observation: Tensor(shape=torch.Size([1, 171]), device=cuda:0, dtype=torch.float64, is_shared=True)},\n",
      "                            batch_size=torch.Size([1]),\n",
      "                            device=cuda:0,\n",
      "                            is_shared=True),\n",
      "                        reward: Tensor(shape=torch.Size([1, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        terminated: Tensor(shape=torch.Size([1, 1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "                        truncated: Tensor(shape=torch.Size([1, 1]), device=cuda:0, dtype=torch.bool, is_shared=True)},\n",
      "                    batch_size=torch.Size([1]),\n",
      "                    device=cuda:0,\n",
      "                    is_shared=True),\n",
      "                player_1: TensorDict(\n",
      "                    fields={\n",
      "                        action_mask: Tensor(shape=torch.Size([1, 11]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "                        done: Tensor(shape=torch.Size([1, 1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "                        mask: Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "                        observation: TensorDict(\n",
      "                            fields={\n",
      "                                observation: Tensor(shape=torch.Size([1, 171]), device=cuda:0, dtype=torch.float64, is_shared=True)},\n",
      "                            batch_size=torch.Size([1]),\n",
      "                            device=cuda:0,\n",
      "                            is_shared=True),\n",
      "                        reward: Tensor(shape=torch.Size([1, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        terminated: Tensor(shape=torch.Size([1, 1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "                        truncated: Tensor(shape=torch.Size([1, 1]), device=cuda:0, dtype=torch.bool, is_shared=True)},\n",
      "                    batch_size=torch.Size([1]),\n",
      "                    device=cuda:0,\n",
      "                    is_shared=True),\n",
      "                terminated: Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "                truncated: Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.bool, is_shared=True)},\n",
      "            batch_size=torch.Size([]),\n",
      "            device=cuda:0,\n",
      "            is_shared=True),\n",
      "        player_0: TensorDict(\n",
      "            fields={\n",
      "                action: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.int64, is_shared=False)},\n",
      "            batch_size=torch.Size([]),\n",
      "            device=None,\n",
      "            is_shared=False)},\n",
      "    batch_size=torch.Size([]),\n",
      "    device=None,\n",
      "    is_shared=False)\n",
      "player_1\n",
      "tensor([False], device='cuda:0')\n",
      "6\n",
      "TensorDict(\n",
      "    fields={\n",
      "        next: TensorDict(\n",
      "            fields={\n",
      "                done: Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "                player_0: TensorDict(\n",
      "                    fields={\n",
      "                        action_mask: Tensor(shape=torch.Size([1, 11]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "                        done: Tensor(shape=torch.Size([1, 1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "                        mask: Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "                        observation: TensorDict(\n",
      "                            fields={\n",
      "                                observation: Tensor(shape=torch.Size([1, 171]), device=cuda:0, dtype=torch.float64, is_shared=True)},\n",
      "                            batch_size=torch.Size([1]),\n",
      "                            device=cuda:0,\n",
      "                            is_shared=True),\n",
      "                        reward: Tensor(shape=torch.Size([1, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        terminated: Tensor(shape=torch.Size([1, 1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "                        truncated: Tensor(shape=torch.Size([1, 1]), device=cuda:0, dtype=torch.bool, is_shared=True)},\n",
      "                    batch_size=torch.Size([1]),\n",
      "                    device=cuda:0,\n",
      "                    is_shared=True),\n",
      "                player_1: TensorDict(\n",
      "                    fields={\n",
      "                        action_mask: Tensor(shape=torch.Size([1, 11]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "                        done: Tensor(shape=torch.Size([1, 1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "                        mask: Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "                        observation: TensorDict(\n",
      "                            fields={\n",
      "                                observation: Tensor(shape=torch.Size([1, 171]), device=cuda:0, dtype=torch.float64, is_shared=True)},\n",
      "                            batch_size=torch.Size([1]),\n",
      "                            device=cuda:0,\n",
      "                            is_shared=True),\n",
      "                        reward: Tensor(shape=torch.Size([1, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        terminated: Tensor(shape=torch.Size([1, 1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "                        truncated: Tensor(shape=torch.Size([1, 1]), device=cuda:0, dtype=torch.bool, is_shared=True)},\n",
      "                    batch_size=torch.Size([1]),\n",
      "                    device=cuda:0,\n",
      "                    is_shared=True),\n",
      "                terminated: Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "                truncated: Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.bool, is_shared=True)},\n",
      "            batch_size=torch.Size([]),\n",
      "            device=cuda:0,\n",
      "            is_shared=True),\n",
      "        player_1: TensorDict(\n",
      "            fields={\n",
      "                action: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.int64, is_shared=False)},\n",
      "            batch_size=torch.Size([]),\n",
      "            device=None,\n",
      "            is_shared=False)},\n",
      "    batch_size=torch.Size([]),\n",
      "    device=None,\n",
      "    is_shared=False)\n",
      "player_0\n",
      "tensor([False], device='cuda:0')\n",
      "0\n",
      "TensorDict(\n",
      "    fields={\n",
      "        next: TensorDict(\n",
      "            fields={\n",
      "                done: Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "                player_0: TensorDict(\n",
      "                    fields={\n",
      "                        action_mask: Tensor(shape=torch.Size([1, 11]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "                        done: Tensor(shape=torch.Size([1, 1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "                        mask: Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "                        observation: TensorDict(\n",
      "                            fields={\n",
      "                                observation: Tensor(shape=torch.Size([1, 171]), device=cuda:0, dtype=torch.float64, is_shared=True)},\n",
      "                            batch_size=torch.Size([1]),\n",
      "                            device=cuda:0,\n",
      "                            is_shared=True),\n",
      "                        reward: Tensor(shape=torch.Size([1, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        terminated: Tensor(shape=torch.Size([1, 1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "                        truncated: Tensor(shape=torch.Size([1, 1]), device=cuda:0, dtype=torch.bool, is_shared=True)},\n",
      "                    batch_size=torch.Size([1]),\n",
      "                    device=cuda:0,\n",
      "                    is_shared=True),\n",
      "                player_1: TensorDict(\n",
      "                    fields={\n",
      "                        action_mask: Tensor(shape=torch.Size([1, 11]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "                        done: Tensor(shape=torch.Size([1, 1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "                        mask: Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "                        observation: TensorDict(\n",
      "                            fields={\n",
      "                                observation: Tensor(shape=torch.Size([1, 171]), device=cuda:0, dtype=torch.float64, is_shared=True)},\n",
      "                            batch_size=torch.Size([1]),\n",
      "                            device=cuda:0,\n",
      "                            is_shared=True),\n",
      "                        reward: Tensor(shape=torch.Size([1, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        terminated: Tensor(shape=torch.Size([1, 1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "                        truncated: Tensor(shape=torch.Size([1, 1]), device=cuda:0, dtype=torch.bool, is_shared=True)},\n",
      "                    batch_size=torch.Size([1]),\n",
      "                    device=cuda:0,\n",
      "                    is_shared=True),\n",
      "                terminated: Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "                truncated: Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.bool, is_shared=True)},\n",
      "            batch_size=torch.Size([]),\n",
      "            device=cuda:0,\n",
      "            is_shared=True),\n",
      "        player_0: TensorDict(\n",
      "            fields={\n",
      "                action: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.int64, is_shared=False)},\n",
      "            batch_size=torch.Size([]),\n",
      "            device=None,\n",
      "            is_shared=False)},\n",
      "    batch_size=torch.Size([]),\n",
      "    device=None,\n",
      "    is_shared=False)\n",
      "player_1\n",
      "tensor([False], device='cuda:0')\n",
      "3\n",
      "TensorDict(\n",
      "    fields={\n",
      "        next: TensorDict(\n",
      "            fields={\n",
      "                done: Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "                player_0: TensorDict(\n",
      "                    fields={\n",
      "                        action_mask: Tensor(shape=torch.Size([1, 11]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "                        done: Tensor(shape=torch.Size([1, 1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "                        mask: Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "                        observation: TensorDict(\n",
      "                            fields={\n",
      "                                observation: Tensor(shape=torch.Size([1, 171]), device=cuda:0, dtype=torch.float64, is_shared=True)},\n",
      "                            batch_size=torch.Size([1]),\n",
      "                            device=cuda:0,\n",
      "                            is_shared=True),\n",
      "                        reward: Tensor(shape=torch.Size([1, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        terminated: Tensor(shape=torch.Size([1, 1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "                        truncated: Tensor(shape=torch.Size([1, 1]), device=cuda:0, dtype=torch.bool, is_shared=True)},\n",
      "                    batch_size=torch.Size([1]),\n",
      "                    device=cuda:0,\n",
      "                    is_shared=True),\n",
      "                player_1: TensorDict(\n",
      "                    fields={\n",
      "                        action_mask: Tensor(shape=torch.Size([1, 11]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "                        done: Tensor(shape=torch.Size([1, 1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "                        mask: Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "                        observation: TensorDict(\n",
      "                            fields={\n",
      "                                observation: Tensor(shape=torch.Size([1, 171]), device=cuda:0, dtype=torch.float64, is_shared=True)},\n",
      "                            batch_size=torch.Size([1]),\n",
      "                            device=cuda:0,\n",
      "                            is_shared=True),\n",
      "                        reward: Tensor(shape=torch.Size([1, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
      "                        terminated: Tensor(shape=torch.Size([1, 1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "                        truncated: Tensor(shape=torch.Size([1, 1]), device=cuda:0, dtype=torch.bool, is_shared=True)},\n",
      "                    batch_size=torch.Size([1]),\n",
      "                    device=cuda:0,\n",
      "                    is_shared=True),\n",
      "                terminated: Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
      "                truncated: Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.bool, is_shared=True)},\n",
      "            batch_size=torch.Size([]),\n",
      "            device=cuda:0,\n",
      "            is_shared=True),\n",
      "        player_1: TensorDict(\n",
      "            fields={\n",
      "                action: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.int64, is_shared=False)},\n",
      "            batch_size=torch.Size([]),\n",
      "            device=None,\n",
      "            is_shared=False)},\n",
      "    batch_size=torch.Size([]),\n",
      "    device=None,\n",
      "    is_shared=False)\n",
      "player_0\n",
      "tensor([True], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from tensordict import TensorDict    \n",
    "state = env.reset()\n",
    "ragent = RandomPolicy(env.action_spec)\n",
    "for agent in env.agent_iter():\n",
    "    print(agent)\n",
    "    print(state[\"done\"])\n",
    "    obs = state[agent]['observation']\n",
    "    action_mask = state[agent]['action_mask']\n",
    "\n",
    "    if state[\"done\"]:\n",
    "        break\n",
    "\n",
    "    action = ragent(obs, action_mask)\n",
    "    print(action)\n",
    "    state = env.step(TensorDict({agent: {\"action\": [action]}}))\n",
    "    print(state)\n",
    "    state = state['next']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Arguments to policy.forward are incompatible with entries in\n    env.observation_spec (got incongruent signatures: fun signature is {'action_mask', 'obs'} vs specs {'player_1', 'player_0'}).\n    If you want TorchRL to automatically wrap your policy with a TensorDictModule\n    then the arguments to policy.forward must correspond one-to-one with entries\n    in env.observation_spec.\n    For more complex behaviour and more control you can consider writing your\n    own TensorDictModule.\n    Check the collector documentation to know more about accepted policies.\n    ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m policy \u001b[38;5;241m=\u001b[39m RandomPolicy(env\u001b[38;5;241m.\u001b[39maction_space)\n\u001b[0;32m----> 2\u001b[0m collector \u001b[38;5;241m=\u001b[39m \u001b[43mSyncDataCollector\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpolicy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframes_per_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframes_per_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtotal_frames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_frames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspaces/HonorsProject/code/.venv/lib/python3.9/site-packages/torchrl/collectors/collectors.py:550\u001b[0m, in \u001b[0;36mSyncDataCollector.__init__\u001b[0;34m(self, create_env_fn, policy, frames_per_batch, total_frames, device, storing_device, policy_device, env_device, create_env_kwargs, max_frames_per_traj, init_random_frames, reset_at_each_iter, postproc, split_trajs, exploration_type, exploration_mode, return_same_td, reset_when_done, interruptor, set_truncated, use_buffers)\u001b[0m\n\u001b[1;32m    547\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset_when_done \u001b[38;5;241m=\u001b[39m reset_when_done\n\u001b[1;32m    548\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_env \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mbatch_size\u001b[38;5;241m.\u001b[39mnumel()\n\u001b[0;32m--> 550\u001b[0m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_weights_fn,) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_policy_and_device\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpolicy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    552\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobservation_spec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobservation_spec\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    553\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    555\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy, nn\u001b[38;5;241m.\u001b[39mModule):\n\u001b[1;32m    556\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy_weights \u001b[38;5;241m=\u001b[39m TensorDict\u001b[38;5;241m.\u001b[39mfrom_module(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy, as_module\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/workspaces/HonorsProject/code/.venv/lib/python3.9/site-packages/torchrl/collectors/collectors.py:155\u001b[0m, in \u001b[0;36mDataCollectorBase._get_policy_and_device\u001b[0;34m(self, policy, observation_spec)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_policy_and_device\u001b[39m(\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    137\u001b[0m     policy: Optional[\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    143\u001b[0m     observation_spec: TensorSpec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    144\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[TensorDictModule, Union[\u001b[38;5;28;01mNone\u001b[39;00m, Callable[[], \u001b[38;5;28mdict\u001b[39m]]]:\n\u001b[1;32m    145\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Util method to get a policy and its device given the collector __init__ inputs.\u001b[39;00m\n\u001b[1;32m    146\u001b[0m \n\u001b[1;32m    147\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    153\u001b[0m \n\u001b[1;32m    154\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 155\u001b[0m     policy \u001b[38;5;241m=\u001b[39m \u001b[43m_make_compatible_policy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpolicy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobservation_spec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43menv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    158\u001b[0m     param_and_buf \u001b[38;5;241m=\u001b[39m TensorDict\u001b[38;5;241m.\u001b[39mfrom_module(policy, as_module\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_weights_fn\u001b[39m(param_and_buf\u001b[38;5;241m=\u001b[39mparam_and_buf):\n",
      "File \u001b[0;32m/workspaces/HonorsProject/code/.venv/lib/python3.9/site-packages/torchrl/envs/utils.py:1500\u001b[0m, in \u001b[0;36m_make_compatible_policy\u001b[0;34m(policy, observation_spec, env, fast_wrap)\u001b[0m\n\u001b[1;32m   1498\u001b[0m         policy \u001b[38;5;241m=\u001b[39m TensorDictModule(policy, in_keys\u001b[38;5;241m=\u001b[39min_keys, out_keys\u001b[38;5;241m=\u001b[39mout_keys)\n\u001b[1;32m   1499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1500\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m   1501\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mArguments to policy.forward are incompatible with entries in\u001b[39m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;124menv.observation_spec (got incongruent signatures: fun signature is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mset\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m vs specs \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mset\u001b[39m(next_observation)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m).\u001b[39m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;124mIf you want TorchRL to automatically wrap your policy with a TensorDictModule\u001b[39m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;124mthen the arguments to policy.forward must correspond one-to-one with entries\u001b[39m\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;124min env.observation_spec.\u001b[39m\n\u001b[1;32m   1506\u001b[0m \u001b[38;5;124mFor more complex behaviour and more control you can consider writing your\u001b[39m\n\u001b[1;32m   1507\u001b[0m \u001b[38;5;124mown TensorDictModule.\u001b[39m\n\u001b[1;32m   1508\u001b[0m \u001b[38;5;124mCheck the collector documentation to know more about accepted policies.\u001b[39m\n\u001b[1;32m   1509\u001b[0m \u001b[38;5;124m\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m   1510\u001b[0m         )\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m policy\n",
      "\u001b[0;31mTypeError\u001b[0m: Arguments to policy.forward are incompatible with entries in\n    env.observation_spec (got incongruent signatures: fun signature is {'action_mask', 'obs'} vs specs {'player_1', 'player_0'}).\n    If you want TorchRL to automatically wrap your policy with a TensorDictModule\n    then the arguments to policy.forward must correspond one-to-one with entries\n    in env.observation_spec.\n    For more complex behaviour and more control you can consider writing your\n    own TensorDictModule.\n    Check the collector documentation to know more about accepted policies.\n    "
     ]
    }
   ],
   "source": [
    "policy = RandomPolicy(env.action_space)\n",
    "collector = SyncDataCollector(\n",
    "    env,\n",
    "    policy=policy,\n",
    "    device=device,\n",
    "    frames_per_batch=frames_per_batch,\n",
    "    total_frames=total_frames,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[159], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m iteration, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(collector):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(iteration, batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobservation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mshape, batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreward\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m/workspaces/HonorsProject/code/.venv/lib/python3.9/site-packages/torchrl/collectors/collectors.py:204\u001b[0m, in \u001b[0;36mDataCollectorBase.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[TensorDictBase]:\n\u001b[0;32m--> 204\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterator()\n",
      "File \u001b[0;32m/workspaces/HonorsProject/code/.venv/lib/python3.9/site-packages/torchrl/collectors/collectors.py:924\u001b[0m, in \u001b[0;36mSyncDataCollector.iterator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_frames \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal_frames:\n\u001b[1;32m    923\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 924\u001b[0m     tensordict_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrollout\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    925\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_frames \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tensordict_out\u001b[38;5;241m.\u001b[39mnumel()\n\u001b[1;32m    926\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_frames \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m total_frames:\n",
      "File \u001b[0;32m/workspaces/HonorsProject/code/.venv/lib/python3.9/site-packages/torchrl/_utils.py:481\u001b[0m, in \u001b[0;36maccept_remote_rref_invocation.<locals>.unpack_rref_and_invoke_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    479\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _os_is_windows \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_distributed_rpc\u001b[38;5;241m.\u001b[39mPyRRef):\n\u001b[1;32m    480\u001b[0m     \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlocal_value()\n\u001b[0;32m--> 481\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspaces/HonorsProject/code/.venv/lib/python3.9/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspaces/HonorsProject/code/.venv/lib/python3.9/site-packages/torchrl/collectors/collectors.py:1046\u001b[0m, in \u001b[0;36mSyncDataCollector.rollout\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1044\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1045\u001b[0m     env_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shuttle\n\u001b[0;32m-> 1046\u001b[0m env_output, env_next_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_and_maybe_reset\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shuttle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m env_output:\n\u001b[1;32m   1049\u001b[0m     \u001b[38;5;66;03m# ad-hoc update shuttle\u001b[39;00m\n\u001b[1;32m   1050\u001b[0m     next_data \u001b[38;5;241m=\u001b[39m env_output\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/workspaces/HonorsProject/code/.venv/lib/python3.9/site-packages/torchrl/envs/common.py:2784\u001b[0m, in \u001b[0;36mEnvBase.step_and_maybe_reset\u001b[0;34m(self, tensordict)\u001b[0m\n\u001b[1;32m   2782\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tensordict\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice:\n\u001b[1;32m   2783\u001b[0m     tensordict \u001b[38;5;241m=\u001b[39m tensordict\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m-> 2784\u001b[0m tensordict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2785\u001b[0m \u001b[38;5;66;03m# done and truncated are in done_keys\u001b[39;00m\n\u001b[1;32m   2786\u001b[0m \u001b[38;5;66;03m# We read if any key is done.\u001b[39;00m\n\u001b[1;32m   2787\u001b[0m tensordict_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_step_mdp(tensordict)\n",
      "File \u001b[0;32m/workspaces/HonorsProject/code/.venv/lib/python3.9/site-packages/torchrl/envs/common.py:1483\u001b[0m, in \u001b[0;36mEnvBase.step\u001b[0;34m(self, tensordict)\u001b[0m\n\u001b[1;32m   1480\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assert_tensordict_shape(tensordict)\n\u001b[1;32m   1481\u001b[0m next_preset \u001b[38;5;241m=\u001b[39m tensordict\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnext\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m-> 1483\u001b[0m next_tensordict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1484\u001b[0m next_tensordict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_step_proc_data(next_tensordict)\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m next_preset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1486\u001b[0m     \u001b[38;5;66;03m# tensordict could already have a \"next\" key\u001b[39;00m\n\u001b[1;32m   1487\u001b[0m     \u001b[38;5;66;03m# this could be done more efficiently by not excluding but just passing\u001b[39;00m\n\u001b[1;32m   1488\u001b[0m     \u001b[38;5;66;03m# the necessary keys\u001b[39;00m\n",
      "File \u001b[0;32m/workspaces/HonorsProject/code/.venv/lib/python3.9/site-packages/torchrl/envs/transforms/transforms.py:779\u001b[0m, in \u001b[0;36mTransformedEnv._step\u001b[0;34m(self, tensordict)\u001b[0m\n\u001b[1;32m    777\u001b[0m next_preset \u001b[38;5;241m=\u001b[39m tensordict\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnext\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    778\u001b[0m tensordict_in \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform\u001b[38;5;241m.\u001b[39minv(tensordict)\n\u001b[0;32m--> 779\u001b[0m next_tensordict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_env\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensordict_in\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    780\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m next_preset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    781\u001b[0m     \u001b[38;5;66;03m# tensordict could already have a \"next\" key\u001b[39;00m\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;66;03m# this could be done more efficiently by not excluding but just passing\u001b[39;00m\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;66;03m# the necessary keys\u001b[39;00m\n\u001b[1;32m    784\u001b[0m     next_tensordict\u001b[38;5;241m.\u001b[39mupdate(\n\u001b[1;32m    785\u001b[0m         next_preset\u001b[38;5;241m.\u001b[39mexclude(\u001b[38;5;241m*\u001b[39mnext_tensordict\u001b[38;5;241m.\u001b[39mkeys(\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[1;32m    786\u001b[0m     )\n",
      "File \u001b[0;32m/workspaces/HonorsProject/code/.venv/lib/python3.9/site-packages/torchrl/envs/libs/pettingzoo.py:616\u001b[0m, in \u001b[0;36mPettingZooWrapper._step\u001b[0;34m(self, tensordict)\u001b[0m\n\u001b[1;32m    602\u001b[0m     (\n\u001b[1;32m    603\u001b[0m         observation_dict,\n\u001b[1;32m    604\u001b[0m         rewards_dict,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    607\u001b[0m         info_dict,\n\u001b[1;32m    608\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_step_parallel(tensordict)\n\u001b[1;32m    609\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    610\u001b[0m     (\n\u001b[1;32m    611\u001b[0m         observation_dict,\n\u001b[1;32m    612\u001b[0m         rewards_dict,\n\u001b[1;32m    613\u001b[0m         terminations_dict,\n\u001b[1;32m    614\u001b[0m         truncations_dict,\n\u001b[1;32m    615\u001b[0m         info_dict,\n\u001b[0;32m--> 616\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_step_aec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;66;03m# We start with zeroed data and fill in the data for alive agents\u001b[39;00m\n\u001b[1;32m    619\u001b[0m tensordict_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcached_step_output_zero\u001b[38;5;241m.\u001b[39mclone()\n",
      "File \u001b[0;32m/workspaces/HonorsProject/code/.venv/lib/python3.9/site-packages/torchrl/envs/libs/pettingzoo.py:761\u001b[0m, in \u001b[0;36mPettingZooWrapper._step_aec\u001b[0;34m(self, tensordict)\u001b[0m\n\u001b[1;32m    757\u001b[0m         group_action \u001b[38;5;241m=\u001b[39m tensordict\u001b[38;5;241m.\u001b[39mget((group, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maction\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m    758\u001b[0m         group_action_np \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_spec[\n\u001b[1;32m    759\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfull_action_spec\u001b[39m\u001b[38;5;124m\"\u001b[39m, group, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maction\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    760\u001b[0m         ]\u001b[38;5;241m.\u001b[39mto_numpy(group_action)\n\u001b[0;32m--> 761\u001b[0m         action \u001b[38;5;241m=\u001b[39m \u001b[43mgroup_action_np\u001b[49m\u001b[43m[\u001b[49m\u001b[43magent_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    762\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_env\u001b[38;5;241m.\u001b[39mstep(action)\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "for iteration, batch in enumerate(collector):\n",
    "    print(iteration, batch[\"observation\"].shape, batch[\"reward\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "RewardSum expects the same number of input and output keys",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchrl\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01menvs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m  DTypeCastTransform\n\u001b[1;32m      2\u001b[0m env \u001b[38;5;241m=\u001b[39m TransformedEnv(\n\u001b[1;32m      3\u001b[0m     base_env,\n\u001b[0;32m----> 4\u001b[0m     \u001b[43mRewardSum\u001b[49m\u001b[43m(\u001b[49m\u001b[43min_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_env\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreward_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43magents\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mepisode_reward\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m      5\u001b[0m     DTypeCastTransform(torch\u001b[38;5;241m.\u001b[39mfloat64, torch\u001b[38;5;241m.\u001b[39mdouble),\n\u001b[1;32m      6\u001b[0m )\n",
      "File \u001b[0;32m/workspaces/HonorsProject/code/.venv/lib/python3.9/site-packages/torchrl/envs/transforms/transforms.py:5403\u001b[0m, in \u001b[0;36mRewardSum.__init__\u001b[0;34m(self, in_keys, out_keys, reset_keys, reward_spec)\u001b[0m\n\u001b[1;32m   5394\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m   5395\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   5396\u001b[0m     in_keys: Sequence[NestedKey] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5400\u001b[0m     reward_spec: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   5401\u001b[0m ):\n\u001b[1;32m   5402\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Initialises the transform. Filters out non-reward input keys and defines output keys.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 5403\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43min_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43min_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout_keys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset_keys \u001b[38;5;241m=\u001b[39m reset_keys\n\u001b[1;32m   5405\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_keys_checked \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/workspaces/HonorsProject/code/.venv/lib/python3.9/site-packages/torchrl/envs/transforms/transforms.py:171\u001b[0m, in \u001b[0;36mTransform.__init__\u001b[0;34m(self, in_keys, out_keys, in_keys_inv, out_keys_inv)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_keys \u001b[38;5;241m=\u001b[39m in_keys\n\u001b[0;32m--> 171\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_keys\u001b[49m \u001b[38;5;241m=\u001b[39m out_keys\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_keys_inv \u001b[38;5;241m=\u001b[39m in_keys_inv\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_keys_inv \u001b[38;5;241m=\u001b[39m out_keys_inv\n",
      "File \u001b[0;32m/workspaces/HonorsProject/code/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1788\u001b[0m, in \u001b[0;36mModule.__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   1786\u001b[0m     buffers[name] \u001b[38;5;241m=\u001b[39m value\n\u001b[1;32m   1787\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1788\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__setattr__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspaces/HonorsProject/code/.venv/lib/python3.9/site-packages/torchrl/envs/transforms/transforms.py:5445\u001b[0m, in \u001b[0;36mRewardSum.out_keys\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   5440\u001b[0m \u001b[38;5;129m@out_keys\u001b[39m\u001b[38;5;241m.\u001b[39msetter\n\u001b[1;32m   5441\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mout_keys\u001b[39m(\u001b[38;5;28mself\u001b[39m, value):\n\u001b[1;32m   5442\u001b[0m     \u001b[38;5;66;03m# we must access the private attribute because this check occurs before\u001b[39;00m\n\u001b[1;32m   5443\u001b[0m     \u001b[38;5;66;03m# the parent env is defined\u001b[39;00m\n\u001b[1;32m   5444\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_keys) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(value):\n\u001b[0;32m-> 5445\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   5446\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRewardSum expects the same number of input and output keys\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   5447\u001b[0m         )\n\u001b[1;32m   5448\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5449\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, (\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n",
      "\u001b[0;31mValueError\u001b[0m: RewardSum expects the same number of input and output keys"
     ]
    }
   ],
   "source": [
    "from torchrl.envs.transforms import  DTypeCastTransform\n",
    "env = TransformedEnv(\n",
    "    base_env,\n",
    "    RewardSum(in_keys=base_env.reward_keys, out_keys=[(\"agents\", \"episode_reward\")]),\n",
    "    DTypeCastTransform(torch.float64, torch.double),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        agents: TensorDict(\n",
       "            fields={\n",
       "                action_mask: Tensor(shape=torch.Size([2, 11]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
       "                done: Tensor(shape=torch.Size([2, 1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
       "                episode_reward: Tensor(shape=torch.Size([2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
       "                mask: Tensor(shape=torch.Size([2]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
       "                observation: TensorDict(\n",
       "                    fields={\n",
       "                        observation: Tensor(shape=torch.Size([2, 173]), device=cuda:0, dtype=torch.float64, is_shared=True)},\n",
       "                    batch_size=torch.Size([2]),\n",
       "                    device=cuda:0,\n",
       "                    is_shared=True),\n",
       "                terminated: Tensor(shape=torch.Size([2, 1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
       "                truncated: Tensor(shape=torch.Size([2, 1]), device=cuda:0, dtype=torch.bool, is_shared=True)},\n",
       "            batch_size=torch.Size([2]),\n",
       "            device=cuda:0,\n",
       "            is_shared=True),\n",
       "        done: Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
       "        terminated: Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
       "        truncated: Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.bool, is_shared=True)},\n",
       "    batch_size=torch.Size([]),\n",
       "    device=cuda:0,\n",
       "    is_shared=True)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'bias'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m policy_net \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mSequential(\u001b[43mMultiAgentMLP\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_agent_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m173\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# n_obs_per_agent\u001b[39;49;00m\n\u001b[1;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_agent_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m11\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# 2 * n_actions_per_agents\u001b[39;49;00m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_agents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcentralised\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# the policies are decentralised (ie each agent will act from its observation)\u001b[39;49;00m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshare_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdepth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_cells\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mactivation_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTanh\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m     13\u001b[0m )\n",
      "File \u001b[0;32m/workspaces/HonorsProject/code/.venv/lib/python3.9/site-packages/torchrl/modules/models/multiagent.py:419\u001b[0m, in \u001b[0;36mMultiAgentMLP.__init__\u001b[0;34m(self, n_agent_inputs, n_agent_outputs, n_agents, centralized, share_params, device, depth, num_cells, activation_class, **kwargs)\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation_class \u001b[38;5;241m=\u001b[39m activation_class\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdepth \u001b[38;5;241m=\u001b[39m depth\n\u001b[0;32m--> 419\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_agents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_agents\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    421\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcentralized\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcentralized\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    422\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshare_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshare_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    423\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    424\u001b[0m \u001b[43m    \u001b[49m\u001b[43magent_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    425\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    426\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspaces/HonorsProject/code/.venv/lib/python3.9/site-packages/torchrl/modules/models/multiagent.py:62\u001b[0m, in \u001b[0;36mMultiAgentNetBase.__init__\u001b[0;34m(self, n_agents, centralized, share_params, agent_dim, vmap_randomness, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magent_dim \u001b[38;5;241m=\u001b[39m agent_dim\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_vmap_randomness \u001b[38;5;241m=\u001b[39m vmap_randomness\n\u001b[0;32m---> 62\u001b[0m agent_networks \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_single_net(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_agents \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshare_params \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     65\u001b[0m ]\n\u001b[1;32m     66\u001b[0m initialized \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m agent_networks[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mparameters():\n",
      "File \u001b[0;32m/workspaces/HonorsProject/code/.venv/lib/python3.9/site-packages/torchrl/modules/models/multiagent.py:63\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magent_dim \u001b[38;5;241m=\u001b[39m agent_dim\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_vmap_randomness \u001b[38;5;241m=\u001b[39m vmap_randomness\n\u001b[1;32m     62\u001b[0m agent_networks \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m---> 63\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_single_net\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_agents \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshare_params \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     65\u001b[0m ]\n\u001b[1;32m     66\u001b[0m initialized \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m agent_networks[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mparameters():\n",
      "File \u001b[0;32m/workspaces/HonorsProject/code/.venv/lib/python3.9/site-packages/torchrl/modules/models/multiagent.py:443\u001b[0m, in \u001b[0;36mMultiAgentMLP._build_single_net\u001b[0;34m(self, device, **kwargs)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcentralized \u001b[38;5;129;01mand\u001b[39;00m n_agent_inputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    442\u001b[0m     n_agent_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_agent_inputs \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_agents\n\u001b[0;32m--> 443\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mMLP\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[43m    \u001b[49m\u001b[43min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_agent_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[43m    \u001b[49m\u001b[43mout_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_agent_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdepth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdepth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_cells\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_cells\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    448\u001b[0m \u001b[43m    \u001b[49m\u001b[43mactivation_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactivation_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    449\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    450\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'bias'"
     ]
    }
   ],
   "source": [
    "policy_net = torch.nn.Sequential(MultiAgentMLP(\n",
    "        n_agent_inputs=173,  # n_obs_per_agent\n",
    "        n_agent_outputs=11,  # 2 * n_actions_per_agents\n",
    "        n_agents=2,\n",
    "        centralised=False,  # the policies are decentralised (ie each agent will act from its observation)\n",
    "        share_params=True,\n",
    "        depth=2,\n",
    "        num_cells=256,\n",
    "        activation_class=torch.nn.Tanh,\n",
    "        device=device,\n",
    "    ),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_module = TensorDictModule(\n",
    "    policy_net,\n",
    "    in_keys=[(\"agents\", \"observation\", \"observation\")],\n",
    "    out_keys=[(\"agents\", \"actions\")],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = ProbabilisticActor(\n",
    "    module=policy_module,\n",
    "    spec=env.action_spec,\n",
    "    in_keys=[(\"agents\", \"actions\")],\n",
    "    out_keys=[env.action_key],\n",
    "    return_log_prob=True,\n",
    ")  # we'll need the log-prob for the PPO loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        action_mask: Tensor(shape=torch.Size([2, 11]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
       "        done: Tensor(shape=torch.Size([2, 1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
       "        episode_reward: Tensor(shape=torch.Size([2, 1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
       "        mask: Tensor(shape=torch.Size([2]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
       "        observation: TensorDict(\n",
       "            fields={\n",
       "                observation: Tensor(shape=torch.Size([2, 173]), device=cuda:0, dtype=torch.float64, is_shared=True)},\n",
       "            batch_size=torch.Size([2]),\n",
       "            device=cuda:0,\n",
       "            is_shared=True),\n",
       "        terminated: Tensor(shape=torch.Size([2, 1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
       "        truncated: Tensor(shape=torch.Size([2, 1]), device=cuda:0, dtype=torch.bool, is_shared=True)},\n",
       "    batch_size=torch.Size([2]),\n",
       "    device=cuda:0,\n",
       "    is_shared=True)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()['agents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformedEnv(\n",
       "    env=PettingZooEnv(),\n",
       "    transform=RewardSum(keys=[('agents', 'reward')]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 must have the same dtype, but got Double and Float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;31mRuntimeError\u001b[0m: TensorDictModule failed with operation\n    Sequential(\n      (0): MultiAgentMLP(\n          MLP(\n            (0): Linear(in_features=173, out_features=256, bias=True)\n            (1): Tanh()\n            (2): Linear(in_features=256, out_features=256, bias=True)\n            (3): Tanh()\n            (4): Linear(in_features=256, out_features=11, bias=True)\n          ),\n          n_agents=2,\n          share_params=True,\n          centralized=False,\n          agent_dim=-2)\n    )\n    in_keys=[('agents', 'observation', 'observation')]\n    out_keys=[('agents', 'actions')].",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mpolicy\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspaces/HonorsProject/code/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspaces/HonorsProject/code/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/workspaces/HonorsProject/code/.venv/lib/python3.9/site-packages/tensordict/nn/common.py:297\u001b[0m, in \u001b[0;36mdispatch.__call__.<locals>.wrapper\u001b[0;34m(_self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    295\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(out[key] \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m dest)\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m out\n\u001b[0;32m--> 297\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_self\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspaces/HonorsProject/code/.venv/lib/python3.9/site-packages/tensordict/_contextlib.py:127\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 127\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspaces/HonorsProject/code/.venv/lib/python3.9/site-packages/tensordict/nn/utils.py:293\u001b[0m, in \u001b[0;36mset_skip_existing.__call__.<locals>.wrapper\u001b[0;34m(_self, tensordict, *args, **kwargs)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    288\u001b[0m     skip_existing()\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(key \u001b[38;5;129;01min\u001b[39;00m tensordict\u001b[38;5;241m.\u001b[39mkeys(\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m out_keys)\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28many\u001b[39m(key \u001b[38;5;129;01min\u001b[39;00m out_keys \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m in_keys)\n\u001b[1;32m    291\u001b[0m ):\n\u001b[1;32m    292\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tensordict\n\u001b[0;32m--> 293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_self\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspaces/HonorsProject/code/.venv/lib/python3.9/site-packages/tensordict/nn/probabilistic.py:654\u001b[0m, in \u001b[0;36mProbabilisticTensorDictSequential.forward\u001b[0;34m(self, tensordict, tensordict_out, **kwargs)\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[38;5;129m@dispatch\u001b[39m(auto_batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    647\u001b[0m \u001b[38;5;129m@set_skip_existing\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    648\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    652\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    653\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m TensorDictBase:\n\u001b[0;32m--> 654\u001b[0m     tensordict_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_dist_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensordict_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    655\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m](tensordict_out, _requires_sample\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_requires_sample)\n",
      "File \u001b[0;32m/workspaces/HonorsProject/code/.venv/lib/python3.9/site-packages/tensordict/nn/probabilistic.py:606\u001b[0m, in \u001b[0;36mProbabilisticTensorDictSequential.get_dist_params\u001b[0;34m(self, tensordict, tensordict_out, **kwargs)\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[38;5;28mtype\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mdefault_interaction_type\n\u001b[1;32m    605\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m set_interaction_type(\u001b[38;5;28mtype\u001b[39m):\n\u001b[0;32m--> 606\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtds\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensordict_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspaces/HonorsProject/code/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspaces/HonorsProject/code/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/workspaces/HonorsProject/code/.venv/lib/python3.9/site-packages/tensordict/nn/common.py:297\u001b[0m, in \u001b[0;36mdispatch.__call__.<locals>.wrapper\u001b[0;34m(_self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    295\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(out[key] \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m dest)\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m out\n\u001b[0;32m--> 297\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_self\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspaces/HonorsProject/code/.venv/lib/python3.9/site-packages/tensordict/nn/utils.py:356\u001b[0m, in \u001b[0;36m_set_skip_existing_None.__call__.<locals>.wrapper\u001b[0;34m(_self, tensordict, *args, **kwargs)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprev \u001b[38;5;241m=\u001b[39m _SKIP_EXISTING\n\u001b[1;32m    355\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 356\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_self\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    358\u001b[0m     _SKIP_EXISTING \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprev\n",
      "File \u001b[0;32m/workspaces/HonorsProject/code/.venv/lib/python3.9/site-packages/tensordict/nn/sequence.py:442\u001b[0m, in \u001b[0;36mTensorDictSequential.forward\u001b[0;34m(self, tensordict, tensordict_out, **kwargs)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(kwargs):\n\u001b[1;32m    441\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule:\n\u001b[0;32m--> 442\u001b[0m         tensordict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    445\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTensorDictSequential does not support keyword arguments other than \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtensordict_out\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or in_keys: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_keys\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwargs\u001b[38;5;241m.\u001b[39mkeys()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    446\u001b[0m     )\n",
      "File \u001b[0;32m/workspaces/HonorsProject/code/.venv/lib/python3.9/site-packages/tensordict/nn/sequence.py:423\u001b[0m, in \u001b[0;36mTensorDictSequential._run_module\u001b[0;34m(self, module, tensordict, **kwargs)\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_module\u001b[39m(\n\u001b[1;32m    415\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    416\u001b[0m     module: TensorDictModule,\n\u001b[1;32m    417\u001b[0m     tensordict: TensorDictBase,\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    419\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    420\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpartial_tolerant \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\n\u001b[1;32m    421\u001b[0m         key \u001b[38;5;129;01min\u001b[39;00m tensordict\u001b[38;5;241m.\u001b[39mkeys(include_nested\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m module\u001b[38;5;241m.\u001b[39min_keys\n\u001b[1;32m    422\u001b[0m     ):\n\u001b[0;32m--> 423\u001b[0m         tensordict \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    424\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpartial_tolerant \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensordict, LazyStackedTensorDict):\n\u001b[1;32m    425\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m sub_td \u001b[38;5;129;01min\u001b[39;00m tensordict\u001b[38;5;241m.\u001b[39mtensordicts:\n",
      "File \u001b[0;32m/workspaces/HonorsProject/code/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspaces/HonorsProject/code/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/workspaces/HonorsProject/code/.venv/lib/python3.9/site-packages/tensordict/nn/common.py:297\u001b[0m, in \u001b[0;36mdispatch.__call__.<locals>.wrapper\u001b[0;34m(_self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    295\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(out[key] \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m dest)\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m out\n\u001b[0;32m--> 297\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_self\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspaces/HonorsProject/code/.venv/lib/python3.9/site-packages/tensordict/nn/utils.py:356\u001b[0m, in \u001b[0;36m_set_skip_existing_None.__call__.<locals>.wrapper\u001b[0;34m(_self, tensordict, *args, **kwargs)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprev \u001b[38;5;241m=\u001b[39m _SKIP_EXISTING\n\u001b[1;32m    355\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 356\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_self\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensordict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    358\u001b[0m     _SKIP_EXISTING \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprev\n",
      "File \u001b[0;32m/workspaces/HonorsProject/code/.venv/lib/python3.9/site-packages/tensordict/nn/common.py:1240\u001b[0m, in \u001b[0;36mTensorDictModule.forward\u001b[0;34m(self, tensordict, tensordict_out, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1238\u001b[0m in_keys \u001b[38;5;241m=\u001b[39m indent(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min_keys=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_keys\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m4\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1239\u001b[0m out_keys \u001b[38;5;241m=\u001b[39m indent(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mout_keys=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_keys\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m4\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1240\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m err \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1241\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTensorDictModule failed with operation\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmodule\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00min_keys\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mout_keys\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1242\u001b[0m )\n",
      "File \u001b[0;32m/workspaces/HonorsProject/code/.venv/lib/python3.9/site-packages/tensordict/nn/common.py:1212\u001b[0m, in \u001b[0;36mTensorDictModule.forward\u001b[0;34m(self, tensordict, tensordict_out, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1206\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[1;32m   1207\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSome tensors that are necessary for the module call may \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1208\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot have not been found in the input tensordict: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1209\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe following inputs are None: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnone_set\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1210\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   1211\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1212\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[1;32m   1213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensors, (\u001b[38;5;28mdict\u001b[39m, TensorDictBase)) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\n\u001b[1;32m   1214\u001b[0m     key \u001b[38;5;129;01min\u001b[39;00m tensors \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_keys\n\u001b[1;32m   1215\u001b[0m ):\n\u001b[1;32m   1216\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensors, \u001b[38;5;28mdict\u001b[39m):\n",
      "File \u001b[0;32m/workspaces/HonorsProject/code/.venv/lib/python3.9/site-packages/tensordict/nn/common.py:1198\u001b[0m, in \u001b[0;36mTensorDictModule.forward\u001b[0;34m(self, tensordict, tensordict_out, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1196\u001b[0m     tensors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(tensordict\u001b[38;5;241m.\u001b[39mget(in_key, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m in_key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39min_keys)\n\u001b[1;32m   1197\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1198\u001b[0m     tensors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1199\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m   1200\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(tensor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m tensor \u001b[38;5;129;01min\u001b[39;00m tensors) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(err):\n",
      "File \u001b[0;32m/workspaces/HonorsProject/code/.venv/lib/python3.9/site-packages/tensordict/nn/common.py:1154\u001b[0m, in \u001b[0;36mTensorDictModule._call_module\u001b[0;34m(self, tensors, **kwargs)\u001b[0m\n\u001b[1;32m   1151\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_call_module\u001b[39m(\n\u001b[1;32m   1152\u001b[0m     \u001b[38;5;28mself\u001b[39m, tensors: Sequence[Tensor], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any\n\u001b[1;32m   1153\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor \u001b[38;5;241m|\u001b[39m Sequence[Tensor]:\n\u001b[0;32m-> 1154\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1155\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/workspaces/HonorsProject/code/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspaces/HonorsProject/code/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/workspaces/HonorsProject/code/.venv/lib/python3.9/site-packages/torch/nn/modules/container.py:219\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 219\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/workspaces/HonorsProject/code/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspaces/HonorsProject/code/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/workspaces/HonorsProject/code/.venv/lib/python3.9/site-packages/torchrl/modules/models/multiagent.py:147\u001b[0m, in \u001b[0;36mMultiAgentNetBase.forward\u001b[0;34m(self, *inputs)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;66;03m# If parameters are shared, agents use the same network\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams\u001b[38;5;241m.\u001b[39mto_module(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_empty_net):\n\u001b[0;32m--> 147\u001b[0m         output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_empty_net\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcentralized:\n\u001b[1;32m    150\u001b[0m         \u001b[38;5;66;03m# If the parameters are shared, and it is centralized, all agents will have the same output\u001b[39;00m\n\u001b[1;32m    151\u001b[0m         \u001b[38;5;66;03m# We expand it to maintain the agent dimension, but values will be the same for all agents\u001b[39;00m\n\u001b[1;32m    152\u001b[0m         n_agent_outputs \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m/workspaces/HonorsProject/code/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspaces/HonorsProject/code/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/workspaces/HonorsProject/code/.venv/lib/python3.9/site-packages/torchrl/modules/models/models.py:296\u001b[0m, in \u001b[0;36mMLP.forward\u001b[0;34m(self, *inputs)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(inputs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    294\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m (torch\u001b[38;5;241m.\u001b[39mcat([\u001b[38;5;241m*\u001b[39minputs], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m),)\n\u001b[0;32m--> 296\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_features, Number):\n\u001b[1;32m    298\u001b[0m     out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m*\u001b[39mout\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_features)\n",
      "File \u001b[0;32m/workspaces/HonorsProject/code/.venv/lib/python3.9/site-packages/torch/nn/modules/container.py:219\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 219\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/workspaces/HonorsProject/code/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspaces/HonorsProject/code/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/workspaces/HonorsProject/code/.venv/lib/python3.9/site-packages/torch/nn/modules/linear.py:117\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 must have the same dtype, but got Double and Float"
     ]
    }
   ],
   "source": [
    "policy(env.reset())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
